{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ltsHY9dFy9-"
   },
   "source": [
    "## Pose Estimation Walkthrough\n",
    "\n",
    "this notebook contains a note while toying with data and the result, also the steps to produce the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-Bpcwei3jlQ",
    "outputId": "3adbf9c7-0143-46a9-ee4c-7d9c95cb4fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import syft as sy\n",
    "import numpy as np\n",
    "from util import connect_to_workers\n",
    "\n",
    "hook = sy.TorchHook(torch)  # hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "\n",
    "LABEL = ['Standing still', 'Sitting and relaxing', 'Lying down', 'Walking', 'Climbing', 'Running']\n",
    "N_WORKER = 8\n",
    "BATCH_SIZE = 32\n",
    "VALID_SIZE = 0.1\n",
    "GPU_FOUND = torch.cuda.is_available()\n",
    "print(GPU_FOUND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ji1p6BHG-6L9"
   },
   "outputs": [],
   "source": [
    "# simulate another remote client using VirtualWorker\n",
    "workers = connect_to_workers(hook,n_workers = N_WORKER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "issHMnOKGCSe"
   },
   "source": [
    "## Reading data\n",
    "\n",
    "1. Split files detected by glob to train and test\n",
    "2. Read CSV\n",
    "3. Construct Dataset class\n",
    "\n",
    "For the first experiment, i will try to use all features that available so the input will be [1 x 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qi4TznmK_BmA"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "# folder path\n",
    "PATH = 'data/Preprocessed'\n",
    "TEST_PATH = 'test'\n",
    "VALID_SIZE = 0.1\n",
    "# seed for random\n",
    "random.seed(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GoOA2DOa_E2N"
   },
   "outputs": [],
   "source": [
    "files = glob.glob(PATH+\"/*.csv\")\n",
    "test_files = glob.glob(TEST_PATH+\"/*.csv\")\n",
    "\n",
    "# split into train and test\n",
    "# according to note, only 8 data for training, and the rest for testing.\n",
    "# so you need to separate manually, take data from /training/Preprocessed to /test\n",
    "count_valid = math.ceil(VALID_SIZE*len(files))\n",
    "random.shuffle(files)\n",
    "valid_files,train_files, = files[0:count_valid],files[count_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lf177KTS_rNQ",
    "outputId": "219d0bdf-d6cf-4668-e514-d91745cd4d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Preprocessed\\mHealth_subject4.csv\n",
      "types of label inside: [5, 1, 2, 3, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "index_to_read = 3\n",
    "sample_read = []\n",
    "sample_label = []\n",
    "label = []\n",
    "\n",
    "with open(train_files[index_to_read]) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        if int(row[21]) != 0:\n",
    "            if int(row[21]) not in label:\n",
    "                label.append(int(row[21]))\n",
    "            sample_read.append([float(item) for item in row[0:21]])\n",
    "            sample_label.append(int(row[21]))\n",
    "\n",
    "print(train_files[index_to_read])\n",
    "print('types of label inside: {}'.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRQc00BN_0Ci",
    "outputId": "3acee476-d2df-45c7-dce8-bf40db307c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chest \t\t\tLeft Angkle\n",
      "-9.44 \t0.12 \t-0.87 \t-0.92 \t-6.83 \t-3.25 \t-0.52 \t-0.42 \t-0.03 \t86.30 \t-37.38 \t-18.81\n",
      "Label \t\t\tRight Angkle\n",
      "5 \t\t\t-2.48 \t-9.58 \t0.72 \t-0.36 \t-0.44 \t-0.04 \t19.25 \t-31.74 \t57.38\n",
      "\n",
      "Chest \t\t\tLeft Angkle\n",
      "-9.35 \t0.02 \t-1.19 \t-0.55 \t-7.76 \t-4.23 \t-0.48 \t-0.34 \t0.04 \t86.50 \t-43.62 \t-19.48\n",
      "Label \t\t\tRight Angkle\n",
      "1 \t\t\t-2.52 \t-9.57 \t0.66 \t-0.36 \t-0.44 \t-0.04 \t17.79 \t-34.74 \t64.24\n",
      "\n",
      "Chest \t\t\tLeft Angkle\n",
      "-8.83 \t-0.12 \t-0.91 \t0.02 \t-8.41 \t-5.39 \t-0.48 \t-0.34 \t0.04 \t84.41 \t-46.16 \t-21.72\n",
      "Label \t\t\tRight Angkle\n",
      "2 \t\t\t-2.21 \t-9.29 \t0.88 \t-0.36 \t-0.44 \t-0.04 \t16.14 \t-37.38 \t70.73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print sample data\n",
    "for index,rep in enumerate(sample_read[:3]):\n",
    "    print('Chest \\t\\t\\tLeft Angkle')\n",
    "    print('{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f}'.format(*rep))\n",
    "    print('Label \\t\\t\\tRight Angkle')\n",
    "    print('{} \\t\\t\\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f} \\t{:.2f}'.format(label[index],*rep[12:]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0ed6c8JGOqr"
   },
   "source": [
    "### Use Constructed Dataset\n",
    "\n",
    "To make it easy, we create a dataloader for reading and returning value from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZU5qLcsG_1ch",
    "outputId": "9cbf31b2-c1c1-4817-9ddc-347f8dca6b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: 129024\n",
      "valid dataset: 18432\n",
      "test dataset: 36864\n"
     ]
    }
   ],
   "source": [
    "from dataloader import ImuPoseDataset\n",
    "\n",
    "train_dataset = ImuPoseDataset(files=train_files)\n",
    "valid_dataset = ImuPoseDataset(files=valid_files)\n",
    "test_dataset = ImuPoseDataset(files=test_files,return_old_data = True)\n",
    "\n",
    "print(\"train dataset: {}\".format(len(train_dataset)))\n",
    "print(\"valid dataset: {}\".format(len(valid_dataset)))\n",
    "print(\"test dataset: {}\".format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moV73cx3GaGU"
   },
   "source": [
    "### Construct Dataloader\n",
    "\n",
    "To iterate our dataset we will use Pytorch built-in dataloader. Since we are training with federated learning we will need to transform it into federatedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hOHmTabCABBR"
   },
   "outputs": [],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader( train_dataset\n",
    "                                                .federate(workers), # <-- we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                drop_last=True,\n",
    "                                                shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           drop_last=True,\n",
    "                                           shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                           batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HlCQ50Y5AE_I",
    "outputId": "c46c5cd9-0618-481e-da2a-b3e26e879f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VirtualWorker id:worker1 #objects:67>\n",
      "our training data shape: torch.Size([32, 1, 21]), torch.FloatTensor\n",
      "our training label shape: torch.Size([32]), torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "test_iter = iter(federated_train_loader)\n",
    "data,label = next(test_iter)\n",
    "print(data.location)\n",
    "print(\"our training data shape: {}, {}\".format(data.shape,data.type()))\n",
    "print(\"our training label shape: {}, {}\".format(label.shape,label.type()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e1jHvCPGiPy"
   },
   "source": [
    "### CNN for classifier\n",
    "\n",
    "for estimating pose, i will be using shallow CNN. I will be using 3 convolutional layers and 2 fully connected dense layers\n",
    "\n",
    "I use the reference from \n",
    "<b>Lima, Wesllen Sousa, et al. “Human Activity Recognition Using Inertial Sensors in a Smartphone: An Overview.” Sensors, vol. 19, no. 14, 2019, p. 3213.</b> \n",
    "\n",
    "that reference a few methods to solve problems related to this.\n",
    "\n",
    "from\n",
    "Goodfellow, Ian, et al. Deep Learning. 2016. mentioned that in recognizing human activity, CNN can be used for prediction by treating each row as timestamp data and  processed by 1D convolution\n",
    ".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ohejJCIyAGAH"
   },
   "outputs": [],
   "source": [
    "from model import CnnModel\n",
    "\n",
    "model = CnnModel(input_size = 1,num_classes=len(LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6OwsA55iAPiU"
   },
   "outputs": [],
   "source": [
    "# define some global param\n",
    "LEARNING_RATE = 0.01\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xy-cwrMPARzO",
    "outputId": "695770d1-b81c-47fb-b51d-257f334d8e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------\n",
      "Train params: Epochs:300, Batch Size: 32, Learning Rate: 0.01\n",
      "\t\tCheckpoint saved to: /content/drive/My Drive/save_train/checkpoint.pt\n",
      "\t\tSaving Model to: /content/drive/My Drive/save_train/pose_estimator.pt\n",
      "\t\tStart at Epoch: 1\n",
      "Train on CPU\n",
      "--------------------------------------------------------------------------------------------\n",
      "Train Epoch: 1 [15968/129024 (12%)]\tLoss: 0.413485\n",
      "Train Epoch: 1 [31968/129024 (25%)]\tLoss: 0.313112\n",
      "Train Epoch: 1 [47968/129024 (37%)]\tLoss: 0.230080\n",
      "Train Epoch: 1 [63968/129024 (50%)]\tLoss: 0.187671\n",
      "Train Epoch: 1 [79968/129024 (62%)]\tLoss: 0.183072\n",
      "Train Epoch: 1 [95968/129024 (74%)]\tLoss: 0.189482\n",
      "Train Epoch: 1 [111968/129024 (87%)]\tLoss: 0.166172\n",
      "Train Epoch: 1 [127968/129024 (99%)]\tLoss: 0.165491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.164902 \tValidation Loss: 0.309491\n",
      "Validation loss decreased (inf --> 0.309491).  Saving model ...\n",
      "F1-score: 0.901506\t Accuracy:0.900391\t Precission:0.924522\t Recall:0.900391\n",
      "Train Epoch: 2 [15968/129024 (12%)]\tLoss: 0.067866\n",
      "Train Epoch: 2 [31968/129024 (25%)]\tLoss: 0.088048\n",
      "Train Epoch: 2 [47968/129024 (37%)]\tLoss: 0.065223\n",
      "Train Epoch: 2 [63968/129024 (50%)]\tLoss: 0.057096\n",
      "Train Epoch: 2 [79968/129024 (62%)]\tLoss: 0.063528\n",
      "Train Epoch: 2 [95968/129024 (74%)]\tLoss: 0.076427\n",
      "Train Epoch: 2 [111968/129024 (87%)]\tLoss: 0.067586\n",
      "Train Epoch: 2 [127968/129024 (99%)]\tLoss: 0.070087\n",
      "Epoch: 2 \tTraining Loss: 0.070013 \tValidation Loss: 0.236962\n",
      "Validation loss decreased (0.309491 --> 0.236962).  Saving model ...\n",
      "F1-score: 0.920083\t Accuracy:0.919488\t Precission:0.938846\t Recall:0.919488\n",
      "Train Epoch: 3 [15968/129024 (12%)]\tLoss: 0.048194\n",
      "Train Epoch: 3 [31968/129024 (25%)]\tLoss: 0.059102\n",
      "Train Epoch: 3 [47968/129024 (37%)]\tLoss: 0.044862\n",
      "Train Epoch: 3 [63968/129024 (50%)]\tLoss: 0.039372\n",
      "Train Epoch: 3 [79968/129024 (62%)]\tLoss: 0.044989\n",
      "Train Epoch: 3 [95968/129024 (74%)]\tLoss: 0.056869\n",
      "Train Epoch: 3 [111968/129024 (87%)]\tLoss: 0.050469\n",
      "Train Epoch: 3 [127968/129024 (99%)]\tLoss: 0.051473\n",
      "Epoch: 3 \tTraining Loss: 0.051330 \tValidation Loss: 0.231944\n",
      "Validation loss decreased (0.236962 --> 0.231944).  Saving model ...\n",
      "F1-score: 0.930699\t Accuracy:0.930556\t Precission:0.949803\t Recall:0.930556\n",
      "Train Epoch: 4 [15968/129024 (12%)]\tLoss: 0.034958\n",
      "Train Epoch: 4 [31968/129024 (25%)]\tLoss: 0.042897\n",
      "Train Epoch: 4 [47968/129024 (37%)]\tLoss: 0.032998\n",
      "Train Epoch: 4 [63968/129024 (50%)]\tLoss: 0.029503\n",
      "Train Epoch: 4 [79968/129024 (62%)]\tLoss: 0.034623\n",
      "Train Epoch: 4 [95968/129024 (74%)]\tLoss: 0.044645\n",
      "Train Epoch: 4 [111968/129024 (87%)]\tLoss: 0.039657\n",
      "Train Epoch: 4 [127968/129024 (99%)]\tLoss: 0.040803\n",
      "Epoch: 4 \tTraining Loss: 0.040663 \tValidation Loss: 0.245503\n",
      "Train Epoch: 5 [15968/129024 (12%)]\tLoss: 0.029024\n",
      "Train Epoch: 5 [31968/129024 (25%)]\tLoss: 0.036635\n",
      "Train Epoch: 5 [47968/129024 (37%)]\tLoss: 0.027971\n",
      "Train Epoch: 5 [63968/129024 (50%)]\tLoss: 0.025355\n",
      "Train Epoch: 5 [79968/129024 (62%)]\tLoss: 0.029754\n",
      "Train Epoch: 5 [95968/129024 (74%)]\tLoss: 0.039206\n",
      "Train Epoch: 5 [111968/129024 (87%)]\tLoss: 0.034728\n",
      "Train Epoch: 5 [127968/129024 (99%)]\tLoss: 0.034981\n",
      "Epoch: 5 \tTraining Loss: 0.034831 \tValidation Loss: 0.230911\n",
      "Validation loss decreased (0.231944 --> 0.230911).  Saving model ...\n",
      "F1-score: 0.931094\t Accuracy:0.931478\t Precission:0.951129\t Recall:0.931478\n",
      "Train Epoch: 6 [15968/129024 (12%)]\tLoss: 0.029256\n",
      "Train Epoch: 6 [31968/129024 (25%)]\tLoss: 0.033651\n",
      "Train Epoch: 6 [47968/129024 (37%)]\tLoss: 0.025183\n",
      "Train Epoch: 6 [63968/129024 (50%)]\tLoss: 0.022630\n",
      "Train Epoch: 6 [79968/129024 (62%)]\tLoss: 0.026098\n",
      "Train Epoch: 6 [95968/129024 (74%)]\tLoss: 0.034873\n",
      "Train Epoch: 6 [111968/129024 (87%)]\tLoss: 0.030836\n",
      "Train Epoch: 6 [127968/129024 (99%)]\tLoss: 0.031208\n",
      "Epoch: 6 \tTraining Loss: 0.031106 \tValidation Loss: 0.257184\n",
      "Train Epoch: 7 [15968/129024 (12%)]\tLoss: 0.025740\n",
      "Train Epoch: 7 [31968/129024 (25%)]\tLoss: 0.029267\n",
      "Train Epoch: 7 [47968/129024 (37%)]\tLoss: 0.021848\n",
      "Train Epoch: 7 [63968/129024 (50%)]\tLoss: 0.020260\n",
      "Train Epoch: 7 [79968/129024 (62%)]\tLoss: 0.023581\n",
      "Train Epoch: 7 [95968/129024 (74%)]\tLoss: 0.030861\n",
      "Train Epoch: 7 [111968/129024 (87%)]\tLoss: 0.027564\n",
      "Train Epoch: 7 [127968/129024 (99%)]\tLoss: 0.027973\n",
      "Epoch: 7 \tTraining Loss: 0.027842 \tValidation Loss: 0.319445\n",
      "Train Epoch: 8 [15968/129024 (12%)]\tLoss: 0.022645\n",
      "Train Epoch: 8 [31968/129024 (25%)]\tLoss: 0.026198\n",
      "Train Epoch: 8 [47968/129024 (37%)]\tLoss: 0.019793\n",
      "Train Epoch: 8 [63968/129024 (50%)]\tLoss: 0.018060\n",
      "Train Epoch: 8 [79968/129024 (62%)]\tLoss: 0.020863\n",
      "Train Epoch: 8 [95968/129024 (74%)]\tLoss: 0.027794\n",
      "Train Epoch: 8 [111968/129024 (87%)]\tLoss: 0.024892\n",
      "Train Epoch: 8 [127968/129024 (99%)]\tLoss: 0.025320\n",
      "Epoch: 8 \tTraining Loss: 0.025251 \tValidation Loss: 0.303989\n",
      "Train Epoch: 9 [15968/129024 (12%)]\tLoss: 0.020422\n",
      "Train Epoch: 9 [31968/129024 (25%)]\tLoss: 0.023350\n",
      "Train Epoch: 9 [47968/129024 (37%)]\tLoss: 0.017866\n",
      "Train Epoch: 9 [63968/129024 (50%)]\tLoss: 0.016785\n",
      "Train Epoch: 9 [79968/129024 (62%)]\tLoss: 0.019812\n",
      "Train Epoch: 9 [95968/129024 (74%)]\tLoss: 0.026450\n",
      "Train Epoch: 9 [111968/129024 (87%)]\tLoss: 0.023637\n",
      "Train Epoch: 9 [127968/129024 (99%)]\tLoss: 0.023773\n",
      "Epoch: 9 \tTraining Loss: 0.023691 \tValidation Loss: 0.341506\n",
      "Train Epoch: 10 [15968/129024 (12%)]\tLoss: 0.023250\n",
      "Train Epoch: 10 [31968/129024 (25%)]\tLoss: 0.023611\n",
      "Train Epoch: 10 [47968/129024 (37%)]\tLoss: 0.017251\n",
      "Train Epoch: 10 [63968/129024 (50%)]\tLoss: 0.015994\n",
      "Train Epoch: 10 [79968/129024 (62%)]\tLoss: 0.018969\n",
      "Train Epoch: 10 [95968/129024 (74%)]\tLoss: 0.024718\n",
      "Train Epoch: 10 [111968/129024 (87%)]\tLoss: 0.022131\n",
      "Train Epoch: 10 [127968/129024 (99%)]\tLoss: 0.022290\n",
      "Epoch: 10 \tTraining Loss: 0.022199 \tValidation Loss: 0.408374\n",
      "Train Epoch: 11 [15968/129024 (12%)]\tLoss: 0.019827\n",
      "Train Epoch: 11 [31968/129024 (25%)]\tLoss: 0.022677\n",
      "Train Epoch: 11 [47968/129024 (37%)]\tLoss: 0.017001\n",
      "Train Epoch: 11 [63968/129024 (50%)]\tLoss: 0.015953\n",
      "Train Epoch: 11 [79968/129024 (62%)]\tLoss: 0.018545\n",
      "Train Epoch: 11 [95968/129024 (74%)]\tLoss: 0.023803\n",
      "Train Epoch: 11 [111968/129024 (87%)]\tLoss: 0.021139\n",
      "Train Epoch: 11 [127968/129024 (99%)]\tLoss: 0.021110\n",
      "Epoch: 11 \tTraining Loss: 0.021083 \tValidation Loss: 0.332376\n",
      "Train Epoch: 12 [15968/129024 (12%)]\tLoss: 0.019606\n",
      "Train Epoch: 12 [31968/129024 (25%)]\tLoss: 0.020268\n",
      "Train Epoch: 12 [47968/129024 (37%)]\tLoss: 0.015128\n",
      "Train Epoch: 12 [63968/129024 (50%)]\tLoss: 0.013706\n",
      "Train Epoch: 12 [79968/129024 (62%)]\tLoss: 0.016341\n",
      "Train Epoch: 12 [95968/129024 (74%)]\tLoss: 0.022038\n",
      "Train Epoch: 12 [111968/129024 (87%)]\tLoss: 0.019820\n",
      "Train Epoch: 12 [127968/129024 (99%)]\tLoss: 0.019835\n",
      "Epoch: 12 \tTraining Loss: 0.019814 \tValidation Loss: 0.301611\n",
      "Train Epoch: 13 [15968/129024 (12%)]\tLoss: 0.017777\n",
      "Train Epoch: 13 [31968/129024 (25%)]\tLoss: 0.019316\n",
      "Train Epoch: 13 [47968/129024 (37%)]\tLoss: 0.014247\n",
      "Train Epoch: 13 [63968/129024 (50%)]\tLoss: 0.013731\n",
      "Train Epoch: 13 [79968/129024 (62%)]\tLoss: 0.015515\n",
      "Train Epoch: 13 [95968/129024 (74%)]\tLoss: 0.020446\n",
      "Train Epoch: 13 [111968/129024 (87%)]\tLoss: 0.018297\n",
      "Train Epoch: 13 [127968/129024 (99%)]\tLoss: 0.018435\n",
      "Epoch: 13 \tTraining Loss: 0.018331 \tValidation Loss: 0.375039\n",
      "Train Epoch: 14 [15968/129024 (12%)]\tLoss: 0.017628\n",
      "Train Epoch: 14 [31968/129024 (25%)]\tLoss: 0.018341\n",
      "Train Epoch: 14 [47968/129024 (37%)]\tLoss: 0.013864\n",
      "Train Epoch: 14 [63968/129024 (50%)]\tLoss: 0.013078\n",
      "Train Epoch: 14 [79968/129024 (62%)]\tLoss: 0.015352\n",
      "Train Epoch: 14 [95968/129024 (74%)]\tLoss: 0.019726\n",
      "Train Epoch: 14 [111968/129024 (87%)]\tLoss: 0.017670\n",
      "Train Epoch: 14 [127968/129024 (99%)]\tLoss: 0.017415\n",
      "Epoch: 14 \tTraining Loss: 0.017410 \tValidation Loss: 0.272357\n",
      "Train Epoch: 15 [15968/129024 (12%)]\tLoss: 0.015211\n",
      "Train Epoch: 15 [31968/129024 (25%)]\tLoss: 0.016950\n",
      "Train Epoch: 15 [47968/129024 (37%)]\tLoss: 0.012805\n",
      "Train Epoch: 15 [63968/129024 (50%)]\tLoss: 0.011876\n",
      "Train Epoch: 15 [79968/129024 (62%)]\tLoss: 0.013979\n",
      "Train Epoch: 15 [95968/129024 (74%)]\tLoss: 0.018451\n",
      "Train Epoch: 15 [111968/129024 (87%)]\tLoss: 0.016539\n",
      "Train Epoch: 15 [127968/129024 (99%)]\tLoss: 0.016410\n",
      "Epoch: 15 \tTraining Loss: 0.016428 \tValidation Loss: 0.352503\n",
      "Train Epoch: 16 [15968/129024 (12%)]\tLoss: 0.015677\n",
      "Train Epoch: 16 [31968/129024 (25%)]\tLoss: 0.016538\n",
      "Train Epoch: 16 [47968/129024 (37%)]\tLoss: 0.012584\n",
      "Train Epoch: 16 [63968/129024 (50%)]\tLoss: 0.011864\n",
      "Train Epoch: 16 [79968/129024 (62%)]\tLoss: 0.013536\n",
      "Train Epoch: 16 [95968/129024 (74%)]\tLoss: 0.018464\n",
      "Train Epoch: 16 [111968/129024 (87%)]\tLoss: 0.016409\n",
      "Train Epoch: 16 [127968/129024 (99%)]\tLoss: 0.016401\n",
      "Epoch: 16 \tTraining Loss: 0.016417 \tValidation Loss: 0.289400\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Train Epoch: 17 [15968/129024 (12%)]\tLoss: 0.026504\n",
      "Train Epoch: 17 [31968/129024 (25%)]\tLoss: 0.026839\n",
      "Train Epoch: 17 [47968/129024 (37%)]\tLoss: 0.022921\n",
      "Train Epoch: 17 [63968/129024 (50%)]\tLoss: 0.024342\n",
      "Train Epoch: 17 [79968/129024 (62%)]\tLoss: 0.025458\n",
      "Train Epoch: 17 [95968/129024 (74%)]\tLoss: 0.027850\n",
      "Train Epoch: 17 [111968/129024 (87%)]\tLoss: 0.025683\n",
      "Train Epoch: 17 [127968/129024 (99%)]\tLoss: 0.024165\n",
      "Epoch: 17 \tTraining Loss: 0.024063 \tValidation Loss: 0.167595\n",
      "Validation loss decreased (0.230911 --> 0.167595).  Saving model ...\n",
      "F1-score: 0.949942\t Accuracy:0.951280\t Precission:0.965781\t Recall:0.951280\n",
      "Train Epoch: 18 [15968/129024 (12%)]\tLoss: 0.018927\n",
      "Train Epoch: 18 [31968/129024 (25%)]\tLoss: 0.021225\n",
      "Train Epoch: 18 [47968/129024 (37%)]\tLoss: 0.017473\n",
      "Train Epoch: 18 [63968/129024 (50%)]\tLoss: 0.018956\n",
      "Train Epoch: 18 [79968/129024 (62%)]\tLoss: 0.019817\n",
      "Train Epoch: 18 [95968/129024 (74%)]\tLoss: 0.022458\n",
      "Train Epoch: 18 [111968/129024 (87%)]\tLoss: 0.020712\n",
      "Train Epoch: 18 [127968/129024 (99%)]\tLoss: 0.020094\n",
      "Epoch: 18 \tTraining Loss: 0.020014 \tValidation Loss: 0.156748\n",
      "Validation loss decreased (0.167595 --> 0.156748).  Saving model ...\n",
      "F1-score: 0.952463\t Accuracy:0.953505\t Precission:0.966575\t Recall:0.953505\n",
      "Train Epoch: 19 [15968/129024 (12%)]\tLoss: 0.017657\n",
      "Train Epoch: 19 [31968/129024 (25%)]\tLoss: 0.019372\n",
      "Train Epoch: 19 [47968/129024 (37%)]\tLoss: 0.016119\n",
      "Train Epoch: 19 [63968/129024 (50%)]\tLoss: 0.017532\n",
      "Train Epoch: 19 [79968/129024 (62%)]\tLoss: 0.018489\n",
      "Train Epoch: 19 [95968/129024 (74%)]\tLoss: 0.021330\n",
      "Train Epoch: 19 [111968/129024 (87%)]\tLoss: 0.019611\n",
      "Train Epoch: 19 [127968/129024 (99%)]\tLoss: 0.018917\n",
      "Epoch: 19 \tTraining Loss: 0.018843 \tValidation Loss: 0.152891\n",
      "Validation loss decreased (0.156748 --> 0.152891).  Saving model ...\n",
      "F1-score: 0.953659\t Accuracy:0.954590\t Precission:0.967241\t Recall:0.954590\n",
      "Train Epoch: 20 [15968/129024 (12%)]\tLoss: 0.016469\n",
      "Train Epoch: 20 [31968/129024 (25%)]\tLoss: 0.017685\n",
      "Train Epoch: 20 [47968/129024 (37%)]\tLoss: 0.014806\n",
      "Train Epoch: 20 [63968/129024 (50%)]\tLoss: 0.015855\n",
      "Train Epoch: 20 [79968/129024 (62%)]\tLoss: 0.016683\n",
      "Train Epoch: 20 [95968/129024 (74%)]\tLoss: 0.019542\n",
      "Train Epoch: 20 [111968/129024 (87%)]\tLoss: 0.018089\n",
      "Train Epoch: 20 [127968/129024 (99%)]\tLoss: 0.017438\n",
      "Epoch: 20 \tTraining Loss: 0.017362 \tValidation Loss: 0.141926\n",
      "Validation loss decreased (0.152891 --> 0.141926).  Saving model ...\n",
      "F1-score: 0.955931\t Accuracy:0.956543\t Precission:0.968664\t Recall:0.956543\n",
      "Train Epoch: 21 [15968/129024 (12%)]\tLoss: 0.016290\n",
      "Train Epoch: 21 [31968/129024 (25%)]\tLoss: 0.018662\n",
      "Train Epoch: 21 [47968/129024 (37%)]\tLoss: 0.015374\n",
      "Train Epoch: 21 [63968/129024 (50%)]\tLoss: 0.016143\n",
      "Train Epoch: 21 [79968/129024 (62%)]\tLoss: 0.016565\n",
      "Train Epoch: 21 [95968/129024 (74%)]\tLoss: 0.019536\n",
      "Train Epoch: 21 [111968/129024 (87%)]\tLoss: 0.017825\n",
      "Train Epoch: 21 [127968/129024 (99%)]\tLoss: 0.017041\n",
      "Epoch: 21 \tTraining Loss: 0.017006 \tValidation Loss: 0.143142\n",
      "Train Epoch: 22 [15968/129024 (12%)]\tLoss: 0.015859\n",
      "Train Epoch: 22 [31968/129024 (25%)]\tLoss: 0.015901\n",
      "Train Epoch: 22 [47968/129024 (37%)]\tLoss: 0.013580\n",
      "Train Epoch: 22 [63968/129024 (50%)]\tLoss: 0.013872\n",
      "Train Epoch: 22 [79968/129024 (62%)]\tLoss: 0.014765\n",
      "Train Epoch: 22 [95968/129024 (74%)]\tLoss: 0.017478\n",
      "Train Epoch: 22 [111968/129024 (87%)]\tLoss: 0.015903\n",
      "Train Epoch: 22 [127968/129024 (99%)]\tLoss: 0.015365\n",
      "Epoch: 22 \tTraining Loss: 0.015319 \tValidation Loss: 0.139830\n",
      "Validation loss decreased (0.141926 --> 0.139830).  Saving model ...\n",
      "F1-score: 0.956903\t Accuracy:0.957791\t Precission:0.968178\t Recall:0.957791\n",
      "Train Epoch: 23 [15968/129024 (12%)]\tLoss: 0.015706\n",
      "Train Epoch: 23 [31968/129024 (25%)]\tLoss: 0.016300\n",
      "Train Epoch: 23 [47968/129024 (37%)]\tLoss: 0.013624\n",
      "Train Epoch: 23 [63968/129024 (50%)]\tLoss: 0.013545\n",
      "Train Epoch: 23 [79968/129024 (62%)]\tLoss: 0.014208\n",
      "Train Epoch: 23 [95968/129024 (74%)]\tLoss: 0.017355\n",
      "Train Epoch: 23 [111968/129024 (87%)]\tLoss: 0.015819\n",
      "Train Epoch: 23 [127968/129024 (99%)]\tLoss: 0.015399\n",
      "Epoch: 23 \tTraining Loss: 0.015351 \tValidation Loss: 0.134935\n",
      "Validation loss decreased (0.139830 --> 0.134935).  Saving model ...\n",
      "F1-score: 0.959309\t Accuracy:0.959744\t Precission:0.969754\t Recall:0.959744\n",
      "Train Epoch: 24 [15968/129024 (12%)]\tLoss: 0.015497\n",
      "Train Epoch: 24 [31968/129024 (25%)]\tLoss: 0.017002\n",
      "Train Epoch: 24 [47968/129024 (37%)]\tLoss: 0.014202\n",
      "Train Epoch: 24 [63968/129024 (50%)]\tLoss: 0.013981\n",
      "Train Epoch: 24 [79968/129024 (62%)]\tLoss: 0.014355\n",
      "Train Epoch: 24 [95968/129024 (74%)]\tLoss: 0.017023\n",
      "Train Epoch: 24 [111968/129024 (87%)]\tLoss: 0.015460\n",
      "Train Epoch: 24 [127968/129024 (99%)]\tLoss: 0.015158\n",
      "Epoch: 24 \tTraining Loss: 0.015100 \tValidation Loss: 0.129870\n",
      "Validation loss decreased (0.134935 --> 0.129870).  Saving model ...\n",
      "F1-score: 0.960396\t Accuracy:0.960720\t Precission:0.970249\t Recall:0.960720\n",
      "Train Epoch: 25 [15968/129024 (12%)]\tLoss: 0.013701\n",
      "Train Epoch: 25 [31968/129024 (25%)]\tLoss: 0.014897\n",
      "Train Epoch: 25 [47968/129024 (37%)]\tLoss: 0.012732\n",
      "Train Epoch: 25 [63968/129024 (50%)]\tLoss: 0.012554\n",
      "Train Epoch: 25 [79968/129024 (62%)]\tLoss: 0.013221\n",
      "Train Epoch: 25 [95968/129024 (74%)]\tLoss: 0.016292\n",
      "Train Epoch: 25 [111968/129024 (87%)]\tLoss: 0.014708\n",
      "Train Epoch: 25 [127968/129024 (99%)]\tLoss: 0.014255\n",
      "Epoch: 25 \tTraining Loss: 0.014205 \tValidation Loss: 0.119799\n",
      "Validation loss decreased (0.129870 --> 0.119799).  Saving model ...\n",
      "F1-score: 0.961743\t Accuracy:0.962077\t Precission:0.970311\t Recall:0.962077\n",
      "Train Epoch: 26 [15968/129024 (12%)]\tLoss: 0.013229\n",
      "Train Epoch: 26 [31968/129024 (25%)]\tLoss: 0.014337\n",
      "Train Epoch: 26 [47968/129024 (37%)]\tLoss: 0.012140\n",
      "Train Epoch: 26 [63968/129024 (50%)]\tLoss: 0.012134\n",
      "Train Epoch: 26 [79968/129024 (62%)]\tLoss: 0.012522\n",
      "Train Epoch: 26 [95968/129024 (74%)]\tLoss: 0.015255\n",
      "Train Epoch: 26 [111968/129024 (87%)]\tLoss: 0.013914\n",
      "Train Epoch: 26 [127968/129024 (99%)]\tLoss: 0.013476\n",
      "Epoch: 26 \tTraining Loss: 0.013448 \tValidation Loss: 0.129735\n",
      "Train Epoch: 27 [15968/129024 (12%)]\tLoss: 0.013718\n",
      "Train Epoch: 27 [31968/129024 (25%)]\tLoss: 0.014389\n",
      "Train Epoch: 27 [47968/129024 (37%)]\tLoss: 0.012313\n",
      "Train Epoch: 27 [63968/129024 (50%)]\tLoss: 0.012236\n",
      "Train Epoch: 27 [79968/129024 (62%)]\tLoss: 0.012541\n",
      "Train Epoch: 27 [95968/129024 (74%)]\tLoss: 0.015786\n",
      "Train Epoch: 27 [111968/129024 (87%)]\tLoss: 0.014287\n",
      "Train Epoch: 27 [127968/129024 (99%)]\tLoss: 0.013963\n",
      "Epoch: 27 \tTraining Loss: 0.013955 \tValidation Loss: 0.120025\n",
      "Train Epoch: 28 [15968/129024 (12%)]\tLoss: 0.011756\n",
      "Train Epoch: 28 [31968/129024 (25%)]\tLoss: 0.013257\n",
      "Train Epoch: 28 [47968/129024 (37%)]\tLoss: 0.011272\n",
      "Train Epoch: 28 [63968/129024 (50%)]\tLoss: 0.011220\n",
      "Train Epoch: 28 [79968/129024 (62%)]\tLoss: 0.011775\n",
      "Train Epoch: 28 [95968/129024 (74%)]\tLoss: 0.014689\n",
      "Train Epoch: 28 [111968/129024 (87%)]\tLoss: 0.013257\n",
      "Train Epoch: 28 [127968/129024 (99%)]\tLoss: 0.012946\n",
      "Epoch: 28 \tTraining Loss: 0.012894 \tValidation Loss: 0.135401\n",
      "Train Epoch: 29 [15968/129024 (12%)]\tLoss: 0.013288\n",
      "Train Epoch: 29 [31968/129024 (25%)]\tLoss: 0.013755\n",
      "Train Epoch: 29 [47968/129024 (37%)]\tLoss: 0.011351\n",
      "Train Epoch: 29 [63968/129024 (50%)]\tLoss: 0.011264\n",
      "Train Epoch: 29 [79968/129024 (62%)]\tLoss: 0.011878\n",
      "Train Epoch: 29 [95968/129024 (74%)]\tLoss: 0.014135\n",
      "Train Epoch: 29 [111968/129024 (87%)]\tLoss: 0.012749\n",
      "Train Epoch: 29 [127968/129024 (99%)]\tLoss: 0.012662\n",
      "Epoch: 29 \tTraining Loss: 0.012625 \tValidation Loss: 0.122419\n",
      "Train Epoch: 30 [15968/129024 (12%)]\tLoss: 0.011380\n",
      "Train Epoch: 30 [31968/129024 (25%)]\tLoss: 0.012785\n",
      "Train Epoch: 30 [47968/129024 (37%)]\tLoss: 0.010741\n",
      "Train Epoch: 30 [63968/129024 (50%)]\tLoss: 0.010306\n",
      "Train Epoch: 30 [79968/129024 (62%)]\tLoss: 0.011017\n",
      "Train Epoch: 30 [95968/129024 (74%)]\tLoss: 0.013450\n",
      "Train Epoch: 30 [111968/129024 (87%)]\tLoss: 0.012133\n",
      "Train Epoch: 30 [127968/129024 (99%)]\tLoss: 0.012009\n",
      "Epoch: 30 \tTraining Loss: 0.012002 \tValidation Loss: 0.109925\n",
      "Validation loss decreased (0.119799 --> 0.109925).  Saving model ...\n",
      "F1-score: 0.964422\t Accuracy:0.964572\t Precission:0.972179\t Recall:0.964572\n",
      "Train Epoch: 31 [15968/129024 (12%)]\tLoss: 0.012010\n",
      "Train Epoch: 31 [31968/129024 (25%)]\tLoss: 0.012217\n",
      "Train Epoch: 31 [47968/129024 (37%)]\tLoss: 0.010760\n",
      "Train Epoch: 31 [63968/129024 (50%)]\tLoss: 0.010064\n",
      "Train Epoch: 31 [79968/129024 (62%)]\tLoss: 0.010589\n",
      "Train Epoch: 31 [95968/129024 (74%)]\tLoss: 0.013200\n",
      "Train Epoch: 31 [111968/129024 (87%)]\tLoss: 0.011884\n",
      "Train Epoch: 31 [127968/129024 (99%)]\tLoss: 0.011716\n",
      "Epoch: 31 \tTraining Loss: 0.011694 \tValidation Loss: 0.124566\n",
      "Train Epoch: 32 [15968/129024 (12%)]\tLoss: 0.012163\n",
      "Train Epoch: 32 [31968/129024 (25%)]\tLoss: 0.012447\n",
      "Train Epoch: 32 [47968/129024 (37%)]\tLoss: 0.010283\n",
      "Train Epoch: 32 [63968/129024 (50%)]\tLoss: 0.010022\n",
      "Train Epoch: 32 [79968/129024 (62%)]\tLoss: 0.010606\n",
      "Train Epoch: 32 [95968/129024 (74%)]\tLoss: 0.013525\n",
      "Train Epoch: 32 [111968/129024 (87%)]\tLoss: 0.012114\n",
      "Train Epoch: 32 [127968/129024 (99%)]\tLoss: 0.011839\n",
      "Epoch: 32 \tTraining Loss: 0.011812 \tValidation Loss: 0.124112\n",
      "Train Epoch: 33 [15968/129024 (12%)]\tLoss: 0.010577\n",
      "Train Epoch: 33 [31968/129024 (25%)]\tLoss: 0.011908\n",
      "Train Epoch: 33 [47968/129024 (37%)]\tLoss: 0.009879\n",
      "Train Epoch: 33 [63968/129024 (50%)]\tLoss: 0.009619\n",
      "Train Epoch: 33 [79968/129024 (62%)]\tLoss: 0.010054\n",
      "Train Epoch: 33 [95968/129024 (74%)]\tLoss: 0.012808\n",
      "Train Epoch: 33 [111968/129024 (87%)]\tLoss: 0.011537\n",
      "Train Epoch: 33 [127968/129024 (99%)]\tLoss: 0.011423\n",
      "Epoch: 33 \tTraining Loss: 0.011415 \tValidation Loss: 0.126030\n",
      "Train Epoch: 34 [15968/129024 (12%)]\tLoss: 0.012151\n",
      "Train Epoch: 34 [31968/129024 (25%)]\tLoss: 0.012657\n",
      "Train Epoch: 34 [47968/129024 (37%)]\tLoss: 0.010634\n",
      "Train Epoch: 34 [63968/129024 (50%)]\tLoss: 0.010189\n",
      "Train Epoch: 34 [79968/129024 (62%)]\tLoss: 0.010466\n",
      "Train Epoch: 34 [95968/129024 (74%)]\tLoss: 0.013059\n",
      "Train Epoch: 34 [111968/129024 (87%)]\tLoss: 0.011714\n",
      "Train Epoch: 34 [127968/129024 (99%)]\tLoss: 0.011482\n",
      "Epoch: 34 \tTraining Loss: 0.011412 \tValidation Loss: 0.127035\n",
      "Train Epoch: 35 [15968/129024 (12%)]\tLoss: 0.009985\n",
      "Train Epoch: 35 [31968/129024 (25%)]\tLoss: 0.011708\n",
      "Train Epoch: 35 [47968/129024 (37%)]\tLoss: 0.010166\n",
      "Train Epoch: 35 [63968/129024 (50%)]\tLoss: 0.009729\n",
      "Train Epoch: 35 [79968/129024 (62%)]\tLoss: 0.010121\n",
      "Train Epoch: 35 [95968/129024 (74%)]\tLoss: 0.012543\n",
      "Train Epoch: 35 [111968/129024 (87%)]\tLoss: 0.011205\n",
      "Train Epoch: 35 [127968/129024 (99%)]\tLoss: 0.010973\n",
      "Epoch: 35 \tTraining Loss: 0.010919 \tValidation Loss: 0.129799\n",
      "Train Epoch: 36 [15968/129024 (12%)]\tLoss: 0.011666\n",
      "Train Epoch: 36 [31968/129024 (25%)]\tLoss: 0.011971\n",
      "Train Epoch: 36 [47968/129024 (37%)]\tLoss: 0.009708\n",
      "Train Epoch: 36 [63968/129024 (50%)]\tLoss: 0.009483\n",
      "Train Epoch: 36 [79968/129024 (62%)]\tLoss: 0.009922\n",
      "Train Epoch: 36 [95968/129024 (74%)]\tLoss: 0.012213\n",
      "Train Epoch: 36 [111968/129024 (87%)]\tLoss: 0.010913\n",
      "Train Epoch: 36 [127968/129024 (99%)]\tLoss: 0.010705\n",
      "Epoch: 36 \tTraining Loss: 0.010698 \tValidation Loss: 0.109373\n",
      "Validation loss decreased (0.109925 --> 0.109373).  Saving model ...\n",
      "F1-score: 0.965204\t Accuracy:0.965386\t Precission:0.972870\t Recall:0.965386\n",
      "Train Epoch: 37 [15968/129024 (12%)]\tLoss: 0.009004\n",
      "Train Epoch: 37 [31968/129024 (25%)]\tLoss: 0.010893\n",
      "Train Epoch: 37 [47968/129024 (37%)]\tLoss: 0.009413\n",
      "Train Epoch: 37 [63968/129024 (50%)]\tLoss: 0.009147\n",
      "Train Epoch: 37 [79968/129024 (62%)]\tLoss: 0.009561\n",
      "Train Epoch: 37 [95968/129024 (74%)]\tLoss: 0.011743\n",
      "Train Epoch: 37 [111968/129024 (87%)]\tLoss: 0.010643\n",
      "Train Epoch: 37 [127968/129024 (99%)]\tLoss: 0.010396\n",
      "Epoch: 37 \tTraining Loss: 0.010334 \tValidation Loss: 0.117567\n",
      "Train Epoch: 38 [15968/129024 (12%)]\tLoss: 0.010920\n",
      "Train Epoch: 38 [31968/129024 (25%)]\tLoss: 0.011420\n",
      "Train Epoch: 38 [47968/129024 (37%)]\tLoss: 0.009419\n",
      "Train Epoch: 38 [63968/129024 (50%)]\tLoss: 0.008846\n",
      "Train Epoch: 38 [79968/129024 (62%)]\tLoss: 0.009092\n",
      "Train Epoch: 38 [95968/129024 (74%)]\tLoss: 0.011413\n",
      "Train Epoch: 38 [111968/129024 (87%)]\tLoss: 0.010244\n",
      "Train Epoch: 38 [127968/129024 (99%)]\tLoss: 0.010140\n",
      "Epoch: 38 \tTraining Loss: 0.010092 \tValidation Loss: 0.116868\n",
      "Train Epoch: 39 [15968/129024 (12%)]\tLoss: 0.010029\n",
      "Train Epoch: 39 [31968/129024 (25%)]\tLoss: 0.010779\n",
      "Train Epoch: 39 [47968/129024 (37%)]\tLoss: 0.008892\n",
      "Train Epoch: 39 [63968/129024 (50%)]\tLoss: 0.008437\n",
      "Train Epoch: 39 [79968/129024 (62%)]\tLoss: 0.008846\n",
      "Train Epoch: 39 [95968/129024 (74%)]\tLoss: 0.011362\n",
      "Train Epoch: 39 [111968/129024 (87%)]\tLoss: 0.010184\n",
      "Train Epoch: 39 [127968/129024 (99%)]\tLoss: 0.010039\n",
      "Epoch: 39 \tTraining Loss: 0.010006 \tValidation Loss: 0.126702\n",
      "Train Epoch: 40 [15968/129024 (12%)]\tLoss: 0.009989\n",
      "Train Epoch: 40 [31968/129024 (25%)]\tLoss: 0.011087\n",
      "Train Epoch: 40 [47968/129024 (37%)]\tLoss: 0.009068\n",
      "Train Epoch: 40 [63968/129024 (50%)]\tLoss: 0.008518\n",
      "Train Epoch: 40 [79968/129024 (62%)]\tLoss: 0.009078\n",
      "Train Epoch: 40 [95968/129024 (74%)]\tLoss: 0.011120\n",
      "Train Epoch: 40 [111968/129024 (87%)]\tLoss: 0.010020\n",
      "Train Epoch: 40 [127968/129024 (99%)]\tLoss: 0.009773\n",
      "Epoch: 40 \tTraining Loss: 0.009771 \tValidation Loss: 0.114312\n",
      "Train Epoch: 41 [15968/129024 (12%)]\tLoss: 0.009584\n",
      "Train Epoch: 41 [31968/129024 (25%)]\tLoss: 0.010571\n",
      "Train Epoch: 41 [47968/129024 (37%)]\tLoss: 0.009086\n",
      "Train Epoch: 41 [63968/129024 (50%)]\tLoss: 0.008273\n",
      "Train Epoch: 41 [79968/129024 (62%)]\tLoss: 0.008664\n",
      "Train Epoch: 41 [95968/129024 (74%)]\tLoss: 0.011122\n",
      "Train Epoch: 41 [111968/129024 (87%)]\tLoss: 0.010010\n",
      "Train Epoch: 41 [127968/129024 (99%)]\tLoss: 0.009922\n",
      "Epoch: 41 \tTraining Loss: 0.009898 \tValidation Loss: 0.121774\n",
      "Train Epoch: 42 [15968/129024 (12%)]\tLoss: 0.011222\n",
      "Train Epoch: 42 [31968/129024 (25%)]\tLoss: 0.010502\n",
      "Train Epoch: 42 [47968/129024 (37%)]\tLoss: 0.008786\n",
      "Train Epoch: 42 [63968/129024 (50%)]\tLoss: 0.008213\n",
      "Train Epoch: 42 [79968/129024 (62%)]\tLoss: 0.008816\n",
      "Train Epoch: 42 [95968/129024 (74%)]\tLoss: 0.011188\n",
      "Train Epoch: 42 [111968/129024 (87%)]\tLoss: 0.009962\n",
      "Train Epoch: 42 [127968/129024 (99%)]\tLoss: 0.009761\n",
      "Epoch: 42 \tTraining Loss: 0.009744 \tValidation Loss: 0.127016\n",
      "Train Epoch: 43 [15968/129024 (12%)]\tLoss: 0.008878\n",
      "Train Epoch: 43 [31968/129024 (25%)]\tLoss: 0.010011\n",
      "Train Epoch: 43 [47968/129024 (37%)]\tLoss: 0.008007\n",
      "Train Epoch: 43 [63968/129024 (50%)]\tLoss: 0.007732\n",
      "Train Epoch: 43 [79968/129024 (62%)]\tLoss: 0.008096\n",
      "Train Epoch: 43 [95968/129024 (74%)]\tLoss: 0.010366\n",
      "Train Epoch: 43 [111968/129024 (87%)]\tLoss: 0.009240\n",
      "Train Epoch: 43 [127968/129024 (99%)]\tLoss: 0.009133\n",
      "Epoch: 43 \tTraining Loss: 0.009109 \tValidation Loss: 0.122882\n",
      "Train Epoch: 44 [15968/129024 (12%)]\tLoss: 0.011958\n",
      "Train Epoch: 44 [31968/129024 (25%)]\tLoss: 0.011137\n",
      "Train Epoch: 44 [47968/129024 (37%)]\tLoss: 0.009031\n",
      "Train Epoch: 44 [63968/129024 (50%)]\tLoss: 0.008064\n",
      "Train Epoch: 44 [79968/129024 (62%)]\tLoss: 0.008266\n",
      "Train Epoch: 44 [95968/129024 (74%)]\tLoss: 0.010365\n",
      "Train Epoch: 44 [111968/129024 (87%)]\tLoss: 0.009232\n",
      "Train Epoch: 44 [127968/129024 (99%)]\tLoss: 0.009220\n",
      "Epoch: 44 \tTraining Loss: 0.009248 \tValidation Loss: 0.119330\n",
      "Train Epoch: 45 [15968/129024 (12%)]\tLoss: 0.008347\n",
      "Train Epoch: 45 [31968/129024 (25%)]\tLoss: 0.009007\n",
      "Train Epoch: 45 [47968/129024 (37%)]\tLoss: 0.007568\n",
      "Train Epoch: 45 [63968/129024 (50%)]\tLoss: 0.007189\n",
      "Train Epoch: 45 [79968/129024 (62%)]\tLoss: 0.007564\n",
      "Train Epoch: 45 [95968/129024 (74%)]\tLoss: 0.009988\n",
      "Train Epoch: 45 [111968/129024 (87%)]\tLoss: 0.008965\n",
      "Train Epoch: 45 [127968/129024 (99%)]\tLoss: 0.008765\n",
      "Epoch: 45 \tTraining Loss: 0.008750 \tValidation Loss: 0.129873\n",
      "Train Epoch: 46 [15968/129024 (12%)]\tLoss: 0.009396\n",
      "Train Epoch: 46 [31968/129024 (25%)]\tLoss: 0.009070\n",
      "Train Epoch: 46 [47968/129024 (37%)]\tLoss: 0.007674\n",
      "Train Epoch: 46 [63968/129024 (50%)]\tLoss: 0.007165\n",
      "Train Epoch: 46 [79968/129024 (62%)]\tLoss: 0.007372\n",
      "Train Epoch: 46 [95968/129024 (74%)]\tLoss: 0.009487\n",
      "Train Epoch: 46 [111968/129024 (87%)]\tLoss: 0.008524\n",
      "Train Epoch: 46 [127968/129024 (99%)]\tLoss: 0.008306\n",
      "Epoch: 46 \tTraining Loss: 0.008261 \tValidation Loss: 0.124443\n",
      "Train Epoch: 47 [15968/129024 (12%)]\tLoss: 0.009667\n",
      "Train Epoch: 47 [31968/129024 (25%)]\tLoss: 0.010034\n",
      "Train Epoch: 47 [47968/129024 (37%)]\tLoss: 0.008078\n",
      "Train Epoch: 47 [63968/129024 (50%)]\tLoss: 0.007214\n",
      "Train Epoch: 47 [79968/129024 (62%)]\tLoss: 0.007597\n",
      "Train Epoch: 47 [95968/129024 (74%)]\tLoss: 0.010221\n",
      "Train Epoch: 47 [111968/129024 (87%)]\tLoss: 0.009152\n",
      "Train Epoch: 47 [127968/129024 (99%)]\tLoss: 0.008941\n",
      "Epoch: 47 \tTraining Loss: 0.008961 \tValidation Loss: 0.133377\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Train Epoch: 48 [15968/129024 (12%)]\tLoss: 0.012077\n",
      "Train Epoch: 48 [31968/129024 (25%)]\tLoss: 0.013066\n",
      "Train Epoch: 48 [47968/129024 (37%)]\tLoss: 0.013840\n",
      "Train Epoch: 48 [63968/129024 (50%)]\tLoss: 0.012909\n",
      "Train Epoch: 48 [79968/129024 (62%)]\tLoss: 0.012456\n",
      "Train Epoch: 48 [95968/129024 (74%)]\tLoss: 0.014062\n",
      "Train Epoch: 48 [111968/129024 (87%)]\tLoss: 0.012518\n",
      "Train Epoch: 48 [127968/129024 (99%)]\tLoss: 0.012312\n",
      "Epoch: 48 \tTraining Loss: 0.012247 \tValidation Loss: 0.084888\n",
      "Validation loss decreased (0.109373 --> 0.084888).  Saving model ...\n",
      "F1-score: 0.971883\t Accuracy:0.971788\t Precission:0.976795\t Recall:0.971788\n",
      "Train Epoch: 49 [15968/129024 (12%)]\tLoss: 0.014519\n",
      "Train Epoch: 49 [31968/129024 (25%)]\tLoss: 0.013419\n",
      "Train Epoch: 49 [47968/129024 (37%)]\tLoss: 0.013800\n",
      "Train Epoch: 49 [63968/129024 (50%)]\tLoss: 0.012440\n",
      "Train Epoch: 49 [79968/129024 (62%)]\tLoss: 0.011944\n",
      "Train Epoch: 49 [95968/129024 (74%)]\tLoss: 0.014081\n",
      "Train Epoch: 49 [111968/129024 (87%)]\tLoss: 0.012520\n",
      "Train Epoch: 49 [127968/129024 (99%)]\tLoss: 0.012089\n",
      "Epoch: 49 \tTraining Loss: 0.012077 \tValidation Loss: 0.083855\n",
      "Validation loss decreased (0.084888 --> 0.083855).  Saving model ...\n",
      "F1-score: 0.971947\t Accuracy:0.971788\t Precission:0.976834\t Recall:0.971788\n",
      "Train Epoch: 50 [15968/129024 (12%)]\tLoss: 0.013702\n",
      "Train Epoch: 50 [31968/129024 (25%)]\tLoss: 0.012883\n",
      "Train Epoch: 50 [47968/129024 (37%)]\tLoss: 0.013078\n",
      "Train Epoch: 50 [63968/129024 (50%)]\tLoss: 0.012042\n",
      "Train Epoch: 50 [79968/129024 (62%)]\tLoss: 0.011798\n",
      "Train Epoch: 50 [95968/129024 (74%)]\tLoss: 0.013751\n",
      "Train Epoch: 50 [111968/129024 (87%)]\tLoss: 0.012092\n",
      "Train Epoch: 50 [127968/129024 (99%)]\tLoss: 0.011918\n",
      "Epoch: 50 \tTraining Loss: 0.011915 \tValidation Loss: 0.076625\n",
      "Validation loss decreased (0.083855 --> 0.076625).  Saving model ...\n",
      "F1-score: 0.974273\t Accuracy:0.974175\t Precission:0.978591\t Recall:0.974175\n",
      "Train Epoch: 51 [15968/129024 (12%)]\tLoss: 0.011761\n",
      "Train Epoch: 51 [31968/129024 (25%)]\tLoss: 0.012084\n",
      "Train Epoch: 51 [47968/129024 (37%)]\tLoss: 0.012235\n",
      "Train Epoch: 51 [63968/129024 (50%)]\tLoss: 0.010647\n",
      "Train Epoch: 51 [79968/129024 (62%)]\tLoss: 0.010624\n",
      "Train Epoch: 51 [95968/129024 (74%)]\tLoss: 0.012423\n",
      "Train Epoch: 51 [111968/129024 (87%)]\tLoss: 0.011167\n",
      "Train Epoch: 51 [127968/129024 (99%)]\tLoss: 0.010913\n",
      "Epoch: 51 \tTraining Loss: 0.010878 \tValidation Loss: 0.072561\n",
      "Validation loss decreased (0.076625 --> 0.072561).  Saving model ...\n",
      "F1-score: 0.975274\t Accuracy:0.975260\t Precission:0.979476\t Recall:0.975260\n",
      "Train Epoch: 52 [15968/129024 (12%)]\tLoss: 0.011896\n",
      "Train Epoch: 52 [31968/129024 (25%)]\tLoss: 0.012251\n",
      "Train Epoch: 52 [47968/129024 (37%)]\tLoss: 0.012165\n",
      "Train Epoch: 52 [63968/129024 (50%)]\tLoss: 0.010757\n",
      "Train Epoch: 52 [79968/129024 (62%)]\tLoss: 0.010617\n",
      "Train Epoch: 52 [95968/129024 (74%)]\tLoss: 0.012821\n",
      "Train Epoch: 52 [111968/129024 (87%)]\tLoss: 0.011490\n",
      "Train Epoch: 52 [127968/129024 (99%)]\tLoss: 0.011179\n",
      "Epoch: 52 \tTraining Loss: 0.011172 \tValidation Loss: 0.069812\n",
      "Validation loss decreased (0.072561 --> 0.069812).  Saving model ...\n",
      "F1-score: 0.976339\t Accuracy:0.976183\t Precission:0.980151\t Recall:0.976183\n",
      "Train Epoch: 53 [15968/129024 (12%)]\tLoss: 0.012301\n",
      "Train Epoch: 53 [31968/129024 (25%)]\tLoss: 0.012735\n",
      "Train Epoch: 53 [47968/129024 (37%)]\tLoss: 0.012121\n",
      "Train Epoch: 53 [63968/129024 (50%)]\tLoss: 0.010904\n",
      "Train Epoch: 53 [79968/129024 (62%)]\tLoss: 0.010924\n",
      "Train Epoch: 53 [95968/129024 (74%)]\tLoss: 0.012799\n",
      "Train Epoch: 53 [111968/129024 (87%)]\tLoss: 0.011294\n",
      "Train Epoch: 53 [127968/129024 (99%)]\tLoss: 0.010961\n",
      "Epoch: 53 \tTraining Loss: 0.010959 \tValidation Loss: 0.068495\n",
      "Validation loss decreased (0.069812 --> 0.068495).  Saving model ...\n",
      "F1-score: 0.976125\t Accuracy:0.976128\t Precission:0.980318\t Recall:0.976128\n",
      "Train Epoch: 54 [15968/129024 (12%)]\tLoss: 0.010276\n",
      "Train Epoch: 54 [31968/129024 (25%)]\tLoss: 0.010775\n",
      "Train Epoch: 54 [47968/129024 (37%)]\tLoss: 0.011174\n",
      "Train Epoch: 54 [63968/129024 (50%)]\tLoss: 0.010082\n",
      "Train Epoch: 54 [79968/129024 (62%)]\tLoss: 0.009954\n",
      "Train Epoch: 54 [95968/129024 (74%)]\tLoss: 0.011886\n",
      "Train Epoch: 54 [111968/129024 (87%)]\tLoss: 0.010694\n",
      "Train Epoch: 54 [127968/129024 (99%)]\tLoss: 0.010418\n",
      "Epoch: 54 \tTraining Loss: 0.010428 \tValidation Loss: 0.076559\n",
      "Train Epoch: 55 [15968/129024 (12%)]\tLoss: 0.010471\n",
      "Train Epoch: 55 [31968/129024 (25%)]\tLoss: 0.010890\n",
      "Train Epoch: 55 [47968/129024 (37%)]\tLoss: 0.010771\n",
      "Train Epoch: 55 [63968/129024 (50%)]\tLoss: 0.009908\n",
      "Train Epoch: 55 [79968/129024 (62%)]\tLoss: 0.009724\n",
      "Train Epoch: 55 [95968/129024 (74%)]\tLoss: 0.011850\n",
      "Train Epoch: 55 [111968/129024 (87%)]\tLoss: 0.010584\n",
      "Train Epoch: 55 [127968/129024 (99%)]\tLoss: 0.010284\n",
      "Epoch: 55 \tTraining Loss: 0.010246 \tValidation Loss: 0.078804\n",
      "Train Epoch: 56 [15968/129024 (12%)]\tLoss: 0.010428\n",
      "Train Epoch: 56 [31968/129024 (25%)]\tLoss: 0.011143\n",
      "Train Epoch: 56 [47968/129024 (37%)]\tLoss: 0.010781\n",
      "Train Epoch: 56 [63968/129024 (50%)]\tLoss: 0.009736\n",
      "Train Epoch: 56 [79968/129024 (62%)]\tLoss: 0.009682\n",
      "Train Epoch: 56 [95968/129024 (74%)]\tLoss: 0.011930\n",
      "Train Epoch: 56 [111968/129024 (87%)]\tLoss: 0.010561\n",
      "Train Epoch: 56 [127968/129024 (99%)]\tLoss: 0.010381\n",
      "Epoch: 56 \tTraining Loss: 0.010356 \tValidation Loss: 0.071741\n",
      "Train Epoch: 57 [15968/129024 (12%)]\tLoss: 0.010737\n",
      "Train Epoch: 57 [31968/129024 (25%)]\tLoss: 0.010183\n",
      "Train Epoch: 57 [47968/129024 (37%)]\tLoss: 0.009890\n",
      "Train Epoch: 57 [63968/129024 (50%)]\tLoss: 0.008672\n",
      "Train Epoch: 57 [79968/129024 (62%)]\tLoss: 0.008758\n",
      "Train Epoch: 57 [95968/129024 (74%)]\tLoss: 0.010991\n",
      "Train Epoch: 57 [111968/129024 (87%)]\tLoss: 0.009788\n",
      "Train Epoch: 57 [127968/129024 (99%)]\tLoss: 0.009649\n",
      "Epoch: 57 \tTraining Loss: 0.009601 \tValidation Loss: 0.071931\n",
      "Train Epoch: 58 [15968/129024 (12%)]\tLoss: 0.011088\n",
      "Train Epoch: 58 [31968/129024 (25%)]\tLoss: 0.010570\n",
      "Train Epoch: 58 [47968/129024 (37%)]\tLoss: 0.010301\n",
      "Train Epoch: 58 [63968/129024 (50%)]\tLoss: 0.009279\n",
      "Train Epoch: 58 [79968/129024 (62%)]\tLoss: 0.009231\n",
      "Train Epoch: 58 [95968/129024 (74%)]\tLoss: 0.011391\n",
      "Train Epoch: 58 [111968/129024 (87%)]\tLoss: 0.010187\n",
      "Train Epoch: 58 [127968/129024 (99%)]\tLoss: 0.009919\n",
      "Epoch: 58 \tTraining Loss: 0.009900 \tValidation Loss: 0.072169\n",
      "Train Epoch: 59 [15968/129024 (12%)]\tLoss: 0.010738\n",
      "Train Epoch: 59 [31968/129024 (25%)]\tLoss: 0.010977\n",
      "Train Epoch: 59 [47968/129024 (37%)]\tLoss: 0.010113\n",
      "Train Epoch: 59 [63968/129024 (50%)]\tLoss: 0.008809\n",
      "Train Epoch: 59 [79968/129024 (62%)]\tLoss: 0.008768\n",
      "Train Epoch: 59 [95968/129024 (74%)]\tLoss: 0.011217\n",
      "Train Epoch: 59 [111968/129024 (87%)]\tLoss: 0.009910\n",
      "Train Epoch: 59 [127968/129024 (99%)]\tLoss: 0.009905\n",
      "Epoch: 59 \tTraining Loss: 0.009889 \tValidation Loss: 0.073280\n",
      "Train Epoch: 60 [15968/129024 (12%)]\tLoss: 0.009200\n",
      "Train Epoch: 60 [31968/129024 (25%)]\tLoss: 0.009748\n",
      "Train Epoch: 60 [47968/129024 (37%)]\tLoss: 0.009154\n",
      "Train Epoch: 60 [63968/129024 (50%)]\tLoss: 0.008455\n",
      "Train Epoch: 60 [79968/129024 (62%)]\tLoss: 0.008521\n",
      "Train Epoch: 60 [95968/129024 (74%)]\tLoss: 0.010846\n",
      "Train Epoch: 60 [111968/129024 (87%)]\tLoss: 0.009673\n",
      "Train Epoch: 60 [127968/129024 (99%)]\tLoss: 0.009439\n",
      "Epoch: 60 \tTraining Loss: 0.009429 \tValidation Loss: 0.075087\n",
      "Train Epoch: 61 [15968/129024 (12%)]\tLoss: 0.010179\n",
      "Train Epoch: 61 [31968/129024 (25%)]\tLoss: 0.010221\n",
      "Train Epoch: 61 [47968/129024 (37%)]\tLoss: 0.009859\n",
      "Train Epoch: 61 [63968/129024 (50%)]\tLoss: 0.008852\n",
      "Train Epoch: 61 [79968/129024 (62%)]\tLoss: 0.008798\n",
      "Train Epoch: 61 [95968/129024 (74%)]\tLoss: 0.011077\n",
      "Train Epoch: 61 [111968/129024 (87%)]\tLoss: 0.009912\n",
      "Train Epoch: 61 [127968/129024 (99%)]\tLoss: 0.009762\n",
      "Epoch: 61 \tTraining Loss: 0.009725 \tValidation Loss: 0.073366\n",
      "Train Epoch: 62 [15968/129024 (12%)]\tLoss: 0.010406\n",
      "Train Epoch: 62 [31968/129024 (25%)]\tLoss: 0.010876\n",
      "Train Epoch: 62 [47968/129024 (37%)]\tLoss: 0.010363\n",
      "Train Epoch: 62 [63968/129024 (50%)]\tLoss: 0.009250\n",
      "Train Epoch: 62 [79968/129024 (62%)]\tLoss: 0.009415\n",
      "Train Epoch: 62 [95968/129024 (74%)]\tLoss: 0.011277\n",
      "Train Epoch: 62 [111968/129024 (87%)]\tLoss: 0.010037\n",
      "Train Epoch: 62 [127968/129024 (99%)]\tLoss: 0.009763\n",
      "Epoch: 62 \tTraining Loss: 0.009730 \tValidation Loss: 0.077012\n",
      "Train Epoch: 63 [15968/129024 (12%)]\tLoss: 0.009659\n",
      "Train Epoch: 63 [31968/129024 (25%)]\tLoss: 0.009468\n",
      "Train Epoch: 63 [47968/129024 (37%)]\tLoss: 0.008956\n",
      "Train Epoch: 63 [63968/129024 (50%)]\tLoss: 0.008315\n",
      "Train Epoch: 63 [79968/129024 (62%)]\tLoss: 0.008359\n",
      "Train Epoch: 63 [95968/129024 (74%)]\tLoss: 0.010662\n",
      "Train Epoch: 63 [111968/129024 (87%)]\tLoss: 0.009477\n",
      "Train Epoch: 63 [127968/129024 (99%)]\tLoss: 0.009309\n",
      "Epoch: 63 \tTraining Loss: 0.009296 \tValidation Loss: 0.081442\n",
      "Train Epoch: 64 [15968/129024 (12%)]\tLoss: 0.009837\n",
      "Train Epoch: 64 [31968/129024 (25%)]\tLoss: 0.009829\n",
      "Train Epoch: 64 [47968/129024 (37%)]\tLoss: 0.009433\n",
      "Train Epoch: 64 [63968/129024 (50%)]\tLoss: 0.008464\n",
      "Train Epoch: 64 [79968/129024 (62%)]\tLoss: 0.008497\n",
      "Train Epoch: 64 [95968/129024 (74%)]\tLoss: 0.010722\n",
      "Train Epoch: 64 [111968/129024 (87%)]\tLoss: 0.009533\n",
      "Train Epoch: 64 [127968/129024 (99%)]\tLoss: 0.009302\n",
      "Epoch: 64 \tTraining Loss: 0.009278 \tValidation Loss: 0.076188\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Train Epoch: 65 [15968/129024 (12%)]\tLoss: 0.013147\n",
      "Train Epoch: 65 [31968/129024 (25%)]\tLoss: 0.011907\n",
      "Train Epoch: 65 [47968/129024 (37%)]\tLoss: 0.011657\n",
      "Train Epoch: 65 [63968/129024 (50%)]\tLoss: 0.009779\n",
      "Train Epoch: 65 [79968/129024 (62%)]\tLoss: 0.009720\n",
      "Train Epoch: 65 [95968/129024 (74%)]\tLoss: 0.011955\n",
      "Train Epoch: 65 [111968/129024 (87%)]\tLoss: 0.010566\n",
      "Train Epoch: 65 [127968/129024 (99%)]\tLoss: 0.010086\n",
      "Epoch: 65 \tTraining Loss: 0.010066 \tValidation Loss: 0.070344\n",
      "Train Epoch: 66 [15968/129024 (12%)]\tLoss: 0.011828\n",
      "Train Epoch: 66 [31968/129024 (25%)]\tLoss: 0.011347\n",
      "Train Epoch: 66 [47968/129024 (37%)]\tLoss: 0.010899\n",
      "Train Epoch: 66 [63968/129024 (50%)]\tLoss: 0.009413\n",
      "Train Epoch: 66 [79968/129024 (62%)]\tLoss: 0.009230\n",
      "Train Epoch: 66 [95968/129024 (74%)]\tLoss: 0.011365\n",
      "Train Epoch: 66 [111968/129024 (87%)]\tLoss: 0.010063\n",
      "Train Epoch: 66 [127968/129024 (99%)]\tLoss: 0.009739\n",
      "Epoch: 66 \tTraining Loss: 0.009699 \tValidation Loss: 0.071288\n",
      "Train Epoch: 67 [15968/129024 (12%)]\tLoss: 0.013376\n",
      "Train Epoch: 67 [31968/129024 (25%)]\tLoss: 0.011627\n",
      "Train Epoch: 67 [47968/129024 (37%)]\tLoss: 0.011263\n",
      "Train Epoch: 67 [63968/129024 (50%)]\tLoss: 0.009378\n",
      "Train Epoch: 67 [79968/129024 (62%)]\tLoss: 0.009294\n",
      "Train Epoch: 67 [95968/129024 (74%)]\tLoss: 0.011666\n",
      "Train Epoch: 67 [111968/129024 (87%)]\tLoss: 0.010370\n",
      "Train Epoch: 67 [127968/129024 (99%)]\tLoss: 0.010150\n",
      "Epoch: 67 \tTraining Loss: 0.010193 \tValidation Loss: 0.074111\n",
      "Train Epoch: 68 [15968/129024 (12%)]\tLoss: 0.012086\n",
      "Train Epoch: 68 [31968/129024 (25%)]\tLoss: 0.011005\n",
      "Train Epoch: 68 [47968/129024 (37%)]\tLoss: 0.011224\n",
      "Train Epoch: 68 [63968/129024 (50%)]\tLoss: 0.009394\n",
      "Train Epoch: 68 [79968/129024 (62%)]\tLoss: 0.009279\n",
      "Train Epoch: 68 [95968/129024 (74%)]\tLoss: 0.011275\n",
      "Train Epoch: 68 [111968/129024 (87%)]\tLoss: 0.009948\n",
      "Train Epoch: 68 [127968/129024 (99%)]\tLoss: 0.009632\n",
      "Epoch: 68 \tTraining Loss: 0.009613 \tValidation Loss: 0.070857\n",
      "Train Epoch: 69 [15968/129024 (12%)]\tLoss: 0.012988\n",
      "Train Epoch: 69 [31968/129024 (25%)]\tLoss: 0.012656\n",
      "Train Epoch: 69 [47968/129024 (37%)]\tLoss: 0.011884\n",
      "Train Epoch: 69 [63968/129024 (50%)]\tLoss: 0.010126\n",
      "Train Epoch: 69 [79968/129024 (62%)]\tLoss: 0.009710\n",
      "Train Epoch: 69 [95968/129024 (74%)]\tLoss: 0.011936\n",
      "Train Epoch: 69 [111968/129024 (87%)]\tLoss: 0.010603\n",
      "Train Epoch: 69 [127968/129024 (99%)]\tLoss: 0.010096\n",
      "Epoch: 69 \tTraining Loss: 0.010097 \tValidation Loss: 0.067573\n",
      "Validation loss decreased (0.068495 --> 0.067573).  Saving model ...\n",
      "F1-score: 0.977425\t Accuracy:0.977376\t Precission:0.981637\t Recall:0.977376\n",
      "Train Epoch: 70 [15968/129024 (12%)]\tLoss: 0.011019\n",
      "Train Epoch: 70 [31968/129024 (25%)]\tLoss: 0.010803\n",
      "Train Epoch: 70 [47968/129024 (37%)]\tLoss: 0.010565\n",
      "Train Epoch: 70 [63968/129024 (50%)]\tLoss: 0.008866\n"
     ]
    }
   ],
   "source": [
    "from trainer import train\n",
    "\n",
    "# Construct args for train param\n",
    "args={\n",
    "    \"epoch\":300,\n",
    "    \"batch_size\":BATCH_SIZE,\n",
    "    \"learning_patience\":10,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    'checkpoint':'',\n",
    "    'saved_model_name':'pose_estimator',\n",
    "    'save_folder':'',\n",
    "}\n",
    "\n",
    "# train the Model\n",
    "train(args, model, criterion, optimizer, federated_train_loader,False,valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating againts test dataset\n",
    "\n",
    "after finish training, it will have the training log in the log/train_log folder according to training start time. Checkpoint also saved in log/checkpoint.\n",
    "\n",
    "Now let's evaluate it using another data, to view it's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------\n",
      "Evaluating Model with Batch Size: 1\n",
      "Data for testing: 36864\n",
      "--------------------------------------------------------------------------------------------\n",
      "Evaluating model, please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\temp_iwan\\miniconda3\\envs\\pose_predictor\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\temp_iwan\\miniconda3\\envs\\pose_predictor\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating [499/36864 (1%)]\n",
      "Evaluating [999/36864 (3%)]\n",
      "Evaluating [1499/36864 (4%)]\n",
      "Evaluating [1999/36864 (5%)]\n",
      "Evaluating [2499/36864 (7%)]\n",
      "Evaluating [2999/36864 (8%)]\n",
      "Evaluating [3499/36864 (9%)]\n",
      "Evaluating [3999/36864 (11%)]\n",
      "Evaluating [4499/36864 (12%)]\n",
      "Evaluating [4999/36864 (14%)]\n",
      "Evaluating [5499/36864 (15%)]\n",
      "Evaluating [5999/36864 (16%)]\n",
      "Evaluating [6499/36864 (18%)]\n",
      "Evaluating [6999/36864 (19%)]\n",
      "Evaluating [7499/36864 (20%)]\n",
      "Evaluating [7999/36864 (22%)]\n",
      "Evaluating [8499/36864 (23%)]\n",
      "Evaluating [8999/36864 (24%)]\n",
      "Evaluating [9499/36864 (26%)]\n",
      "Evaluating [9999/36864 (27%)]\n",
      "Evaluating [10499/36864 (28%)]\n",
      "Evaluating [10999/36864 (30%)]\n",
      "Evaluating [11499/36864 (31%)]\n",
      "Evaluating [11999/36864 (33%)]\n",
      "Evaluating [12499/36864 (34%)]\n",
      "Evaluating [12999/36864 (35%)]\n",
      "Evaluating [13499/36864 (37%)]\n",
      "Evaluating [13999/36864 (38%)]\n",
      "Evaluating [14499/36864 (39%)]\n",
      "Evaluating [14999/36864 (41%)]\n",
      "Evaluating [15499/36864 (42%)]\n",
      "Evaluating [15999/36864 (43%)]\n",
      "Evaluating [16499/36864 (45%)]\n",
      "Evaluating [16999/36864 (46%)]\n",
      "Evaluating [17499/36864 (47%)]\n",
      "Evaluating [17999/36864 (49%)]\n",
      "Evaluating [18499/36864 (50%)]\n",
      "Evaluating [18999/36864 (52%)]\n",
      "Evaluating [19499/36864 (53%)]\n",
      "Evaluating [19999/36864 (54%)]\n",
      "Evaluating [20499/36864 (56%)]\n",
      "Evaluating [20999/36864 (57%)]\n",
      "Evaluating [21499/36864 (58%)]\n",
      "Evaluating [21999/36864 (60%)]\n",
      "Evaluating [22499/36864 (61%)]\n",
      "Evaluating [22999/36864 (62%)]\n",
      "Evaluating [23499/36864 (64%)]\n",
      "Evaluating [23999/36864 (65%)]\n",
      "Evaluating [24499/36864 (66%)]\n",
      "Evaluating [24999/36864 (68%)]\n",
      "Evaluating [25499/36864 (69%)]\n",
      "Evaluating [25999/36864 (71%)]\n",
      "Evaluating [26499/36864 (72%)]\n",
      "Evaluating [26999/36864 (73%)]\n",
      "Evaluating [27499/36864 (75%)]\n",
      "Evaluating [27999/36864 (76%)]\n",
      "Evaluating [28499/36864 (77%)]\n",
      "Evaluating [28999/36864 (79%)]\n",
      "Evaluating [29499/36864 (80%)]\n",
      "Evaluating [29999/36864 (81%)]\n",
      "Evaluating [30499/36864 (83%)]\n",
      "Evaluating [30999/36864 (84%)]\n",
      "Evaluating [31499/36864 (85%)]\n",
      "Evaluating [31999/36864 (87%)]\n",
      "Evaluating [32499/36864 (88%)]\n",
      "Evaluating [32999/36864 (90%)]\n",
      "Evaluating [33499/36864 (91%)]\n",
      "Evaluating [33999/36864 (92%)]\n",
      "Evaluating [34499/36864 (94%)]\n",
      "Evaluating [34999/36864 (95%)]\n",
      "Evaluating [35499/36864 (96%)]\n",
      "Evaluating [35999/36864 (98%)]\n",
      "Evaluating [36499/36864 (99%)]\n",
      "--------------------------------------------\n",
      "Model model/pose_estimator.pt Performance:\n",
      "--------------------------------------------\n",
      "F1 Score: 0.9463975694444444\n",
      "Accuracy: 0.9463975694444444\n",
      "Precission: 0.9463975694444444\n",
      "Recall: 0.9463975694444444\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from evaluate import test\n",
    "\n",
    "args={\n",
    "    \"batch_size\":1,\n",
    "    'model_path':'model/pose_estimator.pt',\n",
    "    'save_result':'',\n",
    "    'test_folder':'test',\n",
    "    'include_null_class':False,\n",
    "}\n",
    "\n",
    "test(test_loader, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "the shallow 1D CNN was able to predict pose based on timestamp data with <b>F1-score</b> reaching 94%. But take note that the label class is small only 6, and it doesn't learn outlier data (No activity). For improvement, the Null label can be considered a real class and trained into network to learn it's feature."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pose_estimator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
